{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f10fdd-996a-488a-a24d-e1137f4ccc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "absl-py==2.1.0\n",
    "aiohappyeyeballs==2.4.3\n",
    "aiohttp==3.10.10\n",
    "aiosignal==1.3.1\n",
    "alpha_vantage==3.0.0\n",
    "astunparse==1.6.3\n",
    "attrs==24.2.0\n",
    "beautifulsoup4==4.12.3\n",
    "blinker==1.8.2\n",
    "certifi==2024.8.30\n",
    "charset-normalizer==3.4.0\n",
    "click==8.1.7\n",
    "Flask==3.0.3\n",
    "flatbuffers==24.3.25\n",
    "frozendict==2.4.6\n",
    "frozenlist==1.4.1\n",
    "gast==0.6.0\n",
    "google-pasta==0.2.0\n",
    "grpcio==1.67.0\n",
    "h5py==3.12.1\n",
    "html5lib==1.1\n",
    "idna==3.10\n",
    "itsdangerous==2.2.0\n",
    "Jinja2==3.1.4\n",
    "joblib==1.4.2\n",
    "keras==3.6.0\n",
    "libclang==18.1.1\n",
    "lxml==5.3.0\n",
    "Markdown==3.7\n",
    "markdown-it-py==3.0.0\n",
    "MarkupSafe==3.0.2\n",
    "mdurl==0.1.2\n",
    "ml-dtypes==0.4.1\n",
    "multidict==6.1.0\n",
    "multitasking==0.0.11\n",
    "namex==0.0.8\n",
    "numpy==1.26.4\n",
    "opt_einsum==3.4.0\n",
    "optree==0.13.0\n",
    "packaging==24.1\n",
    "panadas==0.2\n",
    "pandas==2.2.3\n",
    "pandas_ta==0.3.14b0\n",
    "peewee==3.17.7\n",
    "platformdirs==4.3.6\n",
    "propcache==0.2.0\n",
    "protobuf==4.25.5\n",
    "Pygments==2.18.0\n",
    "python-dateutil==2.9.0.post0\n",
    "python-dotenv==1.0.1\n",
    "pytz==2024.2\n",
    "requests==2.32.3\n",
    "rich==13.9.2\n",
    "scikit-learn==1.5.2\n",
    "scipy==1.13.1\n",
    "setuptools==75.2.0\n",
    "six==1.16.0\n",
    "soupsieve==2.6\n",
    "tensorboard==2.17.1\n",
    "tensorboard-data-server==0.7.2\n",
    "tensorflow==2.17.0\n",
    "termcolor==2.5.0\n",
    "threadpoolctl==3.5.0\n",
    "typing_extensions==4.12.2\n",
    "tzdata==2024.2\n",
    "urllib3==2.2.3\n",
    "webencodings==0.5.1\n",
    "Werkzeug==3.0.4\n",
    "wheel==0.44.0\n",
    "wrapt==1.16.0\n",
    "yarl==1.15.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb22ba",
   "metadata": {},
   "source": [
    "# Step 1 :- Making a requirement text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5596b5",
   "metadata": {},
   "source": [
    "# Installing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ee948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas_ta as ta\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Ensure all data is numeric and handle non-numeric values\n",
    "    df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "    df = df.dropna(subset=['close'])\n",
    "\n",
    "    # Add technical indicators\n",
    "    df['SMA'] = ta.sma(df['close'], length=20)  # Simple Moving Average\n",
    "    df['EMA'] = ta.ema(df['close'], length=20)  # Exponential Moving Average\n",
    "    df['RSI'] = ta.rsi(df['close'], length=14)  # Relative Strength Index\n",
    "\n",
    "    # Drop rows with NaN values (due to indicator calculations)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df[['close', 'SMA', 'EMA', 'RSI']])\n",
    "    return scaled_data, scaler\n",
    "\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    # preparing sequences for LSTM model\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        sequences.append(data[i-sequence_length:i, :])\n",
    "        targets.append(data[i, 0])\n",
    "    X = np.array(sequences)\n",
    "    y = np.array(targets)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n",
    "    return X, y\n",
    "\n",
    "def build_bidirectional_lstm_model(input_shape, units=50, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=units, return_sequences=True), input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Bidirectional(LSTM(units=units, return_sequences=True)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Bidirectional(LSTM(units=units, return_sequences=False)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def train_lstm_model(X, y, input_shape, epochs=50, batch_size=32):\n",
    "    model = build_bidirectional_lstm_model(input_shape)\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    model.save('lstm_model.h5')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd952681",
   "metadata": {},
   "source": [
    "# Generated LSTM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc061df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def connect_db():\n",
    "    return sqlite3.connect('predictions.db')\n",
    "\n",
    "def create_table():\n",
    "    with connect_db() as conn:\n",
    "        conn.execute('''CREATE TABLE IF NOT EXISTS predictions\n",
    "                        (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                         symbol TEXT NOT NULL,\n",
    "                         predicted_price REAL NOT NULL,\n",
    "                         date TEXT NOT NULL,\n",
    "                         timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')\n",
    "\n",
    "def store_prediction(symbol, predicted_price, date):\n",
    "    with connect_db() as conn:\n",
    "        conn.execute('INSERT INTO predictions (symbol, predicted_price, date) VALUES (?, ?, ?)',\n",
    "                     (symbol, predicted_price, date))\n",
    "        conn.commit()\n",
    "\n",
    "def query_db(query, args=(), one=False):\n",
    "    with connect_db() as conn:\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cur = conn.execute(query, args)\n",
    "        rv = cur.fetchall()\n",
    "        return (rv[0] if rv else None) if one else rv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a749af3",
   "metadata": {},
   "source": [
    "# Created sqlite database for tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb06c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_live_data(symbol, api_key):\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}&outputsize=full'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if the response contains an error message\n",
    "    if \"Error Message\" in data:\n",
    "        raise ValueError(f\"Error fetching data for symbol {symbol}: {data['Error Message']}\")\n",
    "    if \"Information\" in data:\n",
    "        raise ValueError(f\"Information: {data['Information']}\")\n",
    "\n",
    "    # Extract time series data\n",
    "    if \"Time Series (Daily)\" not in data:\n",
    "        raise ValueError(f\"Unexpected data format for symbol {symbol}\")\n",
    "\n",
    "    time_series = data[\"Time Series (Daily)\"]\n",
    "    df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "    df = df.rename(columns={\n",
    "        \"1. open\": \"open\",\n",
    "        \"2. high\": \"high\",\n",
    "        \"3. low\": \"low\",\n",
    "        \"4. close\": \"close\",\n",
    "        \"5. volume\": \"volume\"\n",
    "    })\n",
    "    df.index.name = 'Date'\n",
    "    df = df.reset_index()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad896f",
   "metadata": {},
   "source": [
    "# Using Api to get stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your environment variables\n",
    "os.environ['ALPHA_VANTAGE_API_KEY'] = '$(YOUR_ALPHA_VANTAGE_API_KEY)'\n",
    "os.environ['NGROK_AUTHTOKEN'] = '$(NGROK_AUTHTOKEN)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530d2182",
   "metadata": {},
   "source": [
    "# Importing environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f02c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pyngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57568e91",
   "metadata": {},
   "source": [
    "# Double check if pyngrok version is latest or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79854e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from flask import Flask, render_template, request\n",
    "from lstm_model import preprocess_data, create_sequences, train_lstm_model\n",
    "from alpha_vantage_data import fetch_live_data\n",
    "from tensorflow.keras.models import load_model\n",
    "from database import store_prediction, query_db\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set ngrok authtoken\n",
    "NGROK_AUTHTOKEN = os.getenv('NGROK_AUTHTOKEN')\n",
    "if not NGROK_AUTHTOKEN:\n",
    "    raise ValueError(\"Please set the NGROK_AUTHTOKEN environment variable in the .env file.\")\n",
    "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Optionally, remove flask_ngrok if not needed\n",
    "# from flask_ngrok import run_with_ngrok\n",
    "# run_with_ngrok(app)\n",
    "\n",
    "# Create a single ngrok tunnel\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"ngrok tunnel URL:\", public_url)\n",
    "\n",
    "# Load your Alpha Vantage API key from environment variable\n",
    "API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set the ALPHA_VANTAGE_API_KEY environment variable in the .env file.\")\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    prediction = None\n",
    "    error = None\n",
    "    symbol = None\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        symbol = request.form.get('symbol', '').upper().strip()\n",
    "\n",
    "        if not symbol:\n",
    "            error = \"Please enter a valid stock symbol.\"\n",
    "            return render_template('index.html', prediction=None, error=error)\n",
    "\n",
    "        try:\n",
    "            # Fetch live stock data using Alpha Vantage\n",
    "            df = fetch_live_data(symbol, API_KEY)\n",
    "            if df.empty:\n",
    "                raise ValueError(f\"No data found for symbol: {symbol}\")\n",
    "\n",
    "            # Preprocess data\n",
    "            scaled_data, scaler = preprocess_data(df)\n",
    "\n",
    "            # Create sequences\n",
    "            sequence_length = 60\n",
    "            X, y = create_sequences(scaled_data, sequence_length=sequence_length)\n",
    "\n",
    "            # Check if model exists; if not, train a new one\n",
    "            model_path = 'lstm_model.h5'\n",
    "            if os.path.exists(model_path):\n",
    "                model = load_model(model_path)\n",
    "            else:\n",
    "                input_shape = (X.shape[1], X.shape[2])\n",
    "                model = train_lstm_model(X, y, input_shape)\n",
    "\n",
    "            # Make prediction\n",
    "            last_sequence = scaled_data[-sequence_length:]\n",
    "            last_sequence = np.reshape(last_sequence, (1, sequence_length, last_sequence.shape[1]))  # Adjust shape to match indicators\n",
    "            predicted_price = model.predict(last_sequence)\n",
    "\n",
    "            # Create a placeholder for the full feature set to inverse transform\n",
    "            full_feature_set = np.zeros((predicted_price.shape[0], scaled_data.shape[1]))\n",
    "            full_feature_set[:, 0] = predicted_price[:, 0]\n",
    "            predicted_price = scaler.inverse_transform(full_feature_set)[:, 0]\n",
    "\n",
    "            prediction = round(float(predicted_price[0]), 2)\n",
    "\n",
    "            # Store the prediction in the database\n",
    "            current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "            store_prediction(symbol, prediction, current_date)\n",
    "\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            return render_template('index.html', prediction=None, error=error)\n",
    "\n",
    "    return render_template('index.html', prediction=prediction, error=error, symbol=symbol)\n",
    "\n",
    "@app.route('/history')\n",
    "def history():\n",
    "    predictions = query_db('SELECT symbol, predicted_price, timestamp FROM predictions ORDER BY timestamp DESC')\n",
    "    return render_template('history.html', predictions=predictions)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15270a",
   "metadata": {},
   "source": [
    "# made a flask app which gives public address to local host running lstm model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
